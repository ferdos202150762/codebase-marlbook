# @package _global_

algorithm:
  _target_: dqn.train.main
  name: "jal_am"
  model:
    _target_: jal_am.model.JointQNetwork
    layers:
      - 64
      - 64
    critic:
      parameter_sharing: True # True/False/List[int] (seps_indices)
      use_orthogonal_init: True
    agent_model:
      base_layers:
        - 64
        - 64
      policy_layers:
        - 64
      use_orthogonal_init: True
    sample_action_value: False
    n_samples: 10

    device : "cpu"  # a pytorch device ("cpu" or "cuda")

  training_start : 2000
  buffer_size : 10000

  optimizer : "Adam"
  lr : 3.e-4
  gamma : 0.99
  batch_size : 128

  grad_clip : null

  use_proper_termination : True  # True/False/'ignore'
  standardize_returns: True

  eps_decay_style: "linear"  # "linear" or "exponential"
  eps_start : 1.0
  eps_end : 0.05
  eps_decay : 6.5  # exponential decay rate (ignored for linear decay)
  greedy_epsilon : 0.05

  target_update_interval_or_tau: 100

